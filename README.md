# Bank Marketing Dataset: Проєкт машинного навчання
### Вступ
Цей репозиторій містить проєкт машинного навчання, спрямований на прогнозування того, чи підпишеться клієнт банку на терміновий депозит. Проєкт побудовано на основі набору даних про банківський маркетинг, отриманий з [UCI Machine Learning Repository](https://www.google.com/url?q=https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Fsahistapatel96%2Fbankadditionalfullcsv). Основна мета — розробити модель класифікації, яка може точно прогнозувати результат маркетингової кампанії, а також надати інструменти для аналізу та інтерпретації прийнятих рішень.

---

### Структура репозиторію
- `notebooks/`: Містить Jupyter Notebook з усім кодом проєкту, від попередньої обробки даних до навчання, оцінки та пояснення моделі.

  - `bank_marketing_project.ipynb`

- `data/`: Містить необроблені та очищені набори даних.

  - `bank-additional-full.csv` (оригінальний набір даних)

---

### Набір даних
Використаний набір даних `bank-additional-full.csv` містить дані про маркетингові кампанії португальського банку. Кожен рядок представляє клієнта, а стовпці — його демографічні, соціально-економічні та інші атрибути, а також результати останнього контакту.

**Основні ознаки:**

- `age`: Вік клієнта.

- `job`: Тип роботи.

- `marital`: Сімейний стан.

- `education`: Рівень освіти.

- `contact`: Тип зв'язку.

- `duration`: Тривалість останнього контакту в секундах. *(Примітка: Цю ознаку було виключено з моделювання, щоб уникнути витоку даних.)*

- `y`: Цільова змінна (yes або no), що вказує, чи підписав клієнт терміновий депозит.

---

### Етапи проєкту
**1. Попередня обробка та аналіз даних (EDA):**

- Вивчення та очищення даних.

- Аналіз розподілу цільової змінної.

- Обробка категоріальних ознак.

**2. Підготовка даних:**

- Розділення даних на тренувальний та валідаційний набори.
  
- Кодування категоріальних ознак.
  
- Масштабування числових ознак.

**3. Навчання моделі:**

- Було протестовано та порівняно чотири моделі: **Логістична регресія**, **kNN**, **Decision Tree** та **XGBoost**.

- Найкращою моделлю виявилася **XGBoost** з ROC AUC 0.8032.

**4. Тюнінг гіперпараметрів:**

- Для моделі XGBoost було проведено тюнінг гіперпараметрів двома методами: Randomized Search (Sklearn) та Bayesian Optimization (Hyperopt).

- Bayesian Optimization показала найкращий результат, підвищивши ROC AUC на валідаційному наборі до 0.8060.

**5. Інтерпретація моделі:**

- Проведено аналіз важливості ознак за допомогою вбудованих інструментів XGBoost, щоб визначити, які ознаки мали найбільший вплив на прогноз.

- Використано бібліотеку SHAP для пояснення передбачень моделі та візуалізації впливу кожної ознаки на окремі прогнози, що дозволило отримати глибше розуміння роботи моделі.

**6. Аналіз помилок:**

- Проведено аналіз помилково-негативних та помилково-позитивних передбачень на валідаційному наборі.

- Виявлено, що модель має значну проблему з помилково-негативними передбаченнями, що вказує на потенційну можливість подальшого покращення шляхом балансування класів.

  ---

### Результати та висновки
- Найкращу продуктивність продемонструвала модель **XGBoost** з параметрами, отриманими за допомогою **Bayesian Optimization**, досягнувши **ROC AUC 0.8060**.

- Аналіз **SHAP** показав, що модель приймає рішення на основі логічних закономірностей. Найбільший вплив мають такі ознаки, як `age`, `euribor3m`, `campaign` та `month`.

- Аналіз помилок виявив, що основна проблема моделі — це висока кількість помилково-негативних передбачень, що вказує на необхідність використання методів для роботи з незбалансованими даними.

---

### Вимоги до проєкту
Для відтворення проєкту вам знадобляться наступні бібліотеки:

- `pandas`

- `numpy`

- `scikit-learn`

- `matplotlib`

- `xgboost`

- `shap`

- `hyperopt`
